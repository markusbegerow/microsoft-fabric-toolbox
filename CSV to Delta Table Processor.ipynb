{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code\n","\n","# Import necessary libraries\n","import os\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import input_file_name, regexp_extract, regexp_replace\n","\n","# Create SparkSession\n","spark = SparkSession.builder \\\n","    .appName(\"CSV to Delta\") \\\n","    .getOrCreate()\n","\n","# Define the directory with CSV files\n","lakehouse_directory = \"\"\n","\n","# Read all CSV files in the directory\n","df = spark.read.csv(lakehouse_directory, header=True, inferSchema=True) \\\n","    .withColumn(\"filename\", input_file_name())\n","\n","# Extract and clean filenames\n","df = df.withColumn(\"filename\", regexp_extract(\"filename\", \".*/([^/?]+)\\?.*\", 1))\n","df = df.withColumn(\"filename\", regexp_replace(\"filename\", \"\\.CSV.*$\", \".CSV\"))\n","\n","# Get a list of unique filenames\n","filename_list = df.select(\"filename\").distinct().collect()\n","csv_files = [row.filename for row in filename_list]\n","\n","# Process each file\n","for filename in csv_files:\n","    file_path = f\"{lakehouse_directory}/{filename}\"\n","    \n","    # Load data from the file\n","    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n","    \n","    # Create table name from the filename\n","    table_name = os.path.splitext(filename)[0]\n","    \n","    # Save as Delta table\n","    df.write.format(\"csv\").mode(\"overwrite\").saveAsTable(table_name)\n","    \n","    print(f\"Processed file {filename} and saved as table {table_name}.\")\n","\n","spark.stop()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8961e527-0b93-4a72-93d3-6d77d30c6939"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"772d7897-ebc8-46b3-8d7e-d5e9fa58495d","known_lakehouses":[{"id":"772d7897-ebc8-46b3-8d7e-d5e9fa58495d"}],"default_lakehouse_name":"dlh_oowv_ire","default_lakehouse_workspace_id":"16ea9d99-b46e-4e68-ae28-6031aef87fb5"}}},"nbformat":4,"nbformat_minor":5}